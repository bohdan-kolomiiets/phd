%
%

\pdfbookmark[1]{Introduction}{intro}
\section*{Introduction}

Surface electromyography (sEMG) is a non-invasive technique for monitoring the electrical activity generated by muscle contractions, with significant applications in rehabilitation, prosthetics, assistive robotics, and human–computer interaction~\cite{Zhou2023}. sEMG signals are widely used to facilitate gesture recognition, control of prosthetic limbs, and functional recovery assessment in neuromuscular disorders~\cite{Xie2024}.

However, the utility of sEMG is constrained by several physiological and technical factors. One of the most critical is electrode placement. Minor changes in electrode positioning can result in substantial variations in signal amplitude and frequency content due to anatomical and physiological variability~\cite{Merletti2020}. In addition, factors like skin impedance, muscle fatigue, and motion artifacts further degrade signal quality~\cite{Plux2022}.

Classical signal processing techniques—such as time-domain and frequency-domain analysis, wavelet transforms, and handcrafted feature extraction—have long been employed for EMG interpretation~\cite{Chowdhury2013}. While these methods offer computational efficiency and domain-specific interpretability, they often fall short in capturing the complex spatiotemporal patterns associated with dynamic or multichannel sEMG data. Their generalization performance is also limited, especially across subjects or sessions~\cite{Phinyomark2019}.

The introduction of deep learning, particularly convolutional neural networks (CNNs), has significantly enhanced the capacity to extract meaningful representations from raw EMG data. CNNs enable automatic hierarchical feature learning, yielding improved classification performance compared to traditional machine learning models such as SVMs or decision trees~\cite{Faust2018}. However, CNNs typically require large, well-labeled datasets to generalize effectively—a constraint that remains a significant bottleneck in biomedical applications, where data acquisition is often expensive and time-consuming~\cite{Wu2022}.

To mitigate this, transfer learning has become a popular strategy. It enables the reuse of models pre-trained on larger datasets to improve performance on smaller, task-specific datasets. Several techniques exist, including fine-tuning the entire model, freezing early layers while adapting the classifier head, or applying domain adaptation methods. These strategies have shown varying degrees of success in sEMG classification, depending on the architecture and dataset used~\cite{Cote2019, Ameri2020}.

Furthermore, recent progress in wearable electronics—such as flexible sensors, edge computing modules, and energy-efficient microcontrollers—has made it feasible to deploy deep learning models for real-time sEMG classification. This technological convergence supports the development of intelligent, embedded systems capable of continuous physical activity monitoring and adaptive neurorehabilitation ~\cite{Shen2020}.

Thus, the current research focuses on optimizing the use of transfer learning in CNN-based sEMG gesture classification, particularly evaluating strategies that can enhance performance with limited subject-specific data.

\section{Statement of the Problem}

Although convolutional neural networks (CNNs) have demonstrated considerable success in electromyographic (EMG) gesture recognition, their performance often degrades when applied across different subjects without subject-specific training. This limitation hinders the development of generalizable EMG-based human–machine interfaces that can be deployed without extensive per-user calibration~\cite{Cote2019, Geng2016}.

Transfer learning offers a promising approach to improve generalization by leveraging knowledge learned from one group of subjects and adapting it to another. However, the practical effectiveness of different transfer learning strategies—such as fine-tuning the full model versus using a fixed feature extractor—remains insufficiently explored in the context of sEMG-based gesture recognition~\cite{Lehmler2021}.

Moreover, existing literature rarely compares these strategies systematically on standardized datasets using rigorous evaluation protocols. This lack of comparative insight creates uncertainty around which approach yields better classification performance and model stability, especially when the amount of available target subject data is limited.

This study addresses these gaps by experimentally evaluating and comparing two transfer learning strategies in a real-world sEMG classification scenario: (1) fine-tuning with the reset of the fully connected (FC) output layer and (2) fine-tuning without resetting the FC layer. We assess each method's effect on classification accuracy and result variance using the 3DC dataset~\cite{Cote2019_3DC}. Additionally, we test whether these strategies reduce the quantity of subject-specific training data required while maintaining or improving model performance.

\section{Dataset}

The \textit{3DC Dataset} dataset comprises surface electromyography (sEMG) recordings collected from 22 able-bodied participants performing eleven distinct hand and wrist gestures. Each subject completed eight repetitions of a predefined gesture sequence, resulting in a substantial volume of labeled gesture data.

The 3DC Dataset was introduced in the work by Côté-Allard et al.~\cite{Cote2019_3DC}, where the authors designed a low-cost, 3D-printed, wireless myoelectric armband known as the 3DC Armband. This device features 10 dry sEMG electrodes and a 9-axis inertial measurement unit (IMU), with a sampling rate of 1000 Hz. The data acquisition protocol involved placing the 3DC Armband on the dominant forearm of each participant, alternating the armband's position relative to the elbow between participants to simulate real-world variability in wearability.

Subjects were instructed to perform eleven gestures—such as wrist flexion, extension, and different hand shapes—each held for 5 seconds per repetition. These recordings were organized into eight continuous cycles of data acquisition, separated by a 5-minute rest period between the fourth and fifth cycles.

Due to the diverse electrode placement protocols used in the original study to simulate real-world variability, substantial intra- and inter-subject signal differences are present. One the one hand, it challenges the generalization capability of learned models, and on the other hand - it makes this dataset a good benchmark for evaluating inter-subject generalization and transfer learning strategies in sEMG-based gesture classification.

\section{Methods}

The research was conducted using the \texttt{LibEMG} Python library~\cite{LibEMG2023}, which provides a unified framework for data loading, preprocessing, training, and evaluation of machine learning models in electromyographic control systems.

As recent deep learning studies suggest, the raw sEMG signal can be ingested directly for gesture classification~\cite{Oskoei2007,Rehman2018,Cote2019}.

Adhering to the already existing best-practices~\cite{Smith2011} and works that use chosen dataset~\cite{Cote2019_3DC,LibEMG2023}, in this study, raw EMG signals are split into 200-sample overlapping windows (with a step size of 100) forming matrixes of size $10 \times 200$ that serves as the input to our CNN. 

The CNN architecture used in this study is based on implementations from works~\cite{Cote2019_3DC,LibEMG2023}. 

The final architecture consists of three convolutional layers, each followed by batch normalization and ReLU activation, with kernel sizes selected to extract both temporal and spatial features. These were followed by a fully connected (FC) output layer of 11 neurons corresponding to gesture classes.

Network weights were initialized using the Glorot uniform strategy and set biases to zero. The network was trained using the Adam optimizer with an initial learning rate of $10^{-3}$ and cosine annealing scheduler. Cross entropy loss was used as the loss function. Early stopping was applied with a patience of four epochs and tolerance threshold of 0.03. A maximum of 50 epochs was allowed during training, although convergence typically occurred within 15 epochs. To ensure reproducibility, all random seeds were explicitly set for PyTorch, NumPy, and Python’s built-in generators.

Three training approaches were evaluated:

\begin{itemize}
    \item \textbf{Intra-subject (single-subject) training}: The model was trained and tested on different gesture repetitions from the same participant. We applied leave-one-out cross-validation strategy for repetitions, choosing one repetition as test set, one repetition as validation set during training, and six for training itself within each subject. Such cross-validation yields 65 folds per subject.
    \item \textbf{Inter-subject (cross-subject) generalization}: The model was trained on 21 subjects and tested on the one excluded subject. The same leave-one-out cross-validation strategy for repetitions was applied per each excluded subject.
    \item \textbf{Transfer learning}: The best pre-trained cross-subject models were fine-tuned on subject-specific data using two strategies: (1) resetting the final FC layer before fine-tuning and (2) preserving the final FC layer weights. All convolutional layers remained trainable during fine-tuning.
\end{itemize}

Additionally, to answer the question of whether transfer learning approach with resetting FC layer still provides better accuracy comparing to when model trained on the subject from the scratch, even with less subject-specific data used for fine-tuning, training approaches ``Intra-subject'' and ``Transfer learning'' were run again with fewer repetitions. So, if before from totally 8 repetitions, 6 of them were used specifically for training, this runs contained 4, 2, and 1 repetitions.

To compare the effectiveness of transfer learning approaches, Wilcoxon signed-rank tests were performed on F1-score distributions.

\section{Results and Discussion}

To evaluate the performance of different training approaches, F1-score was selected as the primary metric. Figure~\ref{fig:boxplot-approaches} presents box-and-whisker plots summarizing the F1-score distributions for inter-subject generalization, intra-subject training, and two transfer learning strategies: fine-tuning with and without resetting the fully connected (FC) layer. The distributions are based on 1232 cross-validation folds per training strategy across all 22 subjects.

\end{multicols}
\begin{Figure}\centering%{l}{\linewidth}
\includegraphics[width=\linewidth]{accuracy_by_approach_8_reps}
\captionof{figure}{Box-and-whisker plots of F1-score distributions across training approaches: inter-subject generalization, intra-subject training, and two variants of transfer learning (with and without fully connected (FC) layer reset). Boxes represent interquartile range (IQR), lines show medians, and dashed lines indicate means. Outliers are shown as individual points.}
\label{fig:boxplot-approaches}
\end{Figure}
\begin{multicols}{2}

The baseline inter-subject approach yielded a mean F1-score of 0.382 ($\sigma = 0.149$), confirming that generalization across subjects is significantly limited due to variability in electrode placement and anatomical differences. In contrast, intra-subject training—where the model is trained and tested on data from the same participant—achieved a dramatically higher mean F1-score of 0.869 ($\sigma = 0.089$).

Fine-tuning pre-trained models using the ``without FC reset'' aproach further improved performance to 0.896 ($\sigma = 0.071$). However, the best result was obtained using the ``with FC reset'' approach, achieving a mean of 0.907 ($\sigma = 0.074$), suggesting that resetting the classifier head enables better adaptation to new subjects. Both transfer learning strategies outperformed intra-subject training, affirming the benefit of leveraging pre-trained representations.

To assess whether transfer learning allowes to reduce the amount of subject-specific data, we performed additional experiments with decreasing numbers of training repetitions. As shown in Figure~\ref{fig:boxplot-reps}, the transfer learning approach with FC layer reset consistently achieves higher F1-scores across all scenarios. While reducing the number of training repetitions to three results in a noticeable decline in accuracy, using four repetitions yields only a modest decrease. This effectively halves the required subject effort compared to using all eight repetitions, without substantially compromising classification accuracy.

\end{multicols}
\begin{Figure}\centering%{l}{\linewidth}
\includegraphics[width=\linewidth]{intra_subject_vs_fine_tuned_by_reps}
\captionof{figure}{Box-and-whisker plots showing the distribution of F1-scores across different numbers of training repetitions (6, 4, 2, 1) for intra-subject training and transfer learning (with fully connected layer reset). Note that repetitions numbers here represent a total number of repetitions consisting of eleven gestures a subject would need to execute. Each box shows the interquartile range and median; dashed lines denote the mean. Outliers are plotted as individual points.}
\label{fig:boxplot-reps}
\end{Figure}
\begin{multicols}{2}

\subsection*{Statistical Significance of Transfer Learning Improvements}

To formally test the impact of transfer learning approaches, we performed Wilcoxon signed-rank tests on the subject-wise mean and standard deviation (STD) of F1-scores.
Significance level was chosen to be $\alpha = 0.05$.

\textbf{Comparison: Intra-subject vs Transfer Learning (without FC reset).}  
The mean F1-score increased from 0.869 to 0.896. Wilcoxon test ($p = 7.87 \times 10^{-6}$) confirms a statistically significant improvement. However, for model stability, the tests yielded $p = 0.0829$, indicating the reduction in STD (from 0.089 to 0.071) is not statistically significant.

\textbf{Comparison: Intra-subject vs Transfer Learning (with FC reset).}  
The mean F1-score improved to 0.907, with Wilcoxon test ($p = 2.38 \times 10^{-7}$) confirming significance. The reduction in STD from 0.089 to 0.074 was also significant ($p = 0.00162$), confirming that this aproach provides both better accuracy and improved model stability.

\textbf{Comparison: Transfer Learning without vs with FC reset.}  
When comparing the two transfer learning approaches, the ``with FC reset'' approach outperformed the ``without reset'' variant with mean F1-scores of 0.907 vs 0.896. Wilcoxon test ($p = 0.000346$) again indicate statistical significance. However, the difference in STD was not statistically significant ($p = 0.118$).

% TODO: add statistical tests for each number of repetitions.

\subsection*{Summary of Findings}

In summary:
\begin{itemize}
    \item Both transfer learning strategies significantly outperform intra-subject training in classification accuracy.
    \item Transfer learning with FC reset is statistically more stable than intra-subject training.
    \item Transfer learning allows for comparable or better performance even when fine-tuning with very limited subject-specific data.
    \item Among the strategies, fine-tuning with FC reset provides the best overall performance in terms of accuracy and stability.
\end{itemize}

These findings validate the efficacy of transfer learning for sEMG gesture recognition and highlight the practical advantage of using pre-trained models for quick subject adaptation, especially in real-time or low-data scenarios.

\subsection{Оформлення таблиць}

Таблиця в одній колонці
\begin{Table}
	\captionof{table}{Average F1-scores and its standard deviations for each training approach}
	\begin{tabularx}{\linewidth}{|l|c|c|c|c|X|}
		\hline   &   &  &  &  &  \\
		\rule{0pt}{10pt} Training approach  & F-score  &	 &	  & &	 \\ 
		\hline 
		\rule{0pt}{10pt} Inter-subject & $0.382 \pm 0.149$ &	 &	  &	  &	 \\ 
		\hline 
		\rule{0pt}{10pt} Intra-subject & $0.869 \pm 0.089$ &   &	  &	  &  \\ 
		\hline 
		\rule{0pt}{10pt} Transfer learning &   &   &	  &	  & \\ 
		\hline 
		\rule{0pt}{10pt}   &	  &  &   &	  &  \\ 
		\hline 
\end{tabularx} \label{radap1725tab1}
\end{Table}

\section{Приклади оформлення окремих елементів статті}

Формули з скрізним номером: 
\begin{equation}\label{radap1725eq1}
p_n(z(\xi)) = \frac{1}{\sqrt{2\pi} v} \exp  \left(-\frac{1}{2}\Bigg(\frac{z(\xi)}{v} \Bigg)^2 \right)
\end{equation}

\begin{equation}\label{radap1725eq2}
p_{cn}(z(\xi)) = \frac{1}{\sqrt{2\pi} v} \exp  \left(-\frac{1}{2}\Bigg(\frac{z(\xi)}{v}-q \Bigg)^2 \right) 
\end{equation}

Декілька рівнянь з позначкою одним номером:
\begin{equation*}
\begin{aligned}
{K_1}\left( {x,y} \right) = {C_1}\left( {x,y} \right) + {n_1}\left( {x,y} \right),\\	
{K_2}\left( {x,y} \right) = {C_2}\left( {x,y} \right) + {n_2}\left( {x,y} \right),
\end{aligned}
\end{equation*}

%\begin{equation}
%\begin{aligned}
%
%\end{aligned}
%\end{equation}

Довгі формули слід записувати у декілька стрічок як це приведено нижче:
\begin{multline}\label{radap1345eq2}
U_{i-1}= \sum\limits_{j=0}^{i-1}\left| r_j - \sum\limits_{h=0}^{g} x_{(j-h)} \nu_h \right|^2 =\\= \sum\limits_{j=0}^{i-2}\left| r_j - \sum\limits_{h=0}^{g} x_{(j-h)} \nu_h \right|^2 +w_{i-1} =\\= U_{i-2} + w_{i-1} 
\end{multline}

Дуже довгі формули, що важко розмістити в одній колонці можна розмістити на всю сторінку як це приведено нижче:

\end{multicols} % Закриваємо розмітку на дві колонки
\begin{multline}
\upsilon({{s}_{x}},{{s}_{y}},{{s}_{z}})\!=\!\frac{\left[{{p}_{\bot }}{{J}_{1}}\left(\sqrt{s_{x}^{2}+s_{y}^{2}}{{r}_{0}}\right){{J}_{0}}({{p}_{\bot }})-\sqrt{s_{x}^{2}+s_{y}^{2}}{{r}_{0}}{{J}_{0}}\left(\sqrt{s_{x}^{2}+s_{y}^{2}}{{r}_{0}}\right){{J}_{1}}({{p}_{\bot }})\right]}{(s_{x}^{2}+s_{y}^{2})r_{0}^{2}-p_{\bot }^{2}}\frac{\omega _{z}^{*}({{s}_{z}})}{\sqrt{s_{x}^{2}+s_{y}^{2}}};  
\end{multline}
\begin{multicols}{2} % Відкриваємо нову розмітку на дві колонки 

Формули без номеру: 
$$
M\left\{ {\ln \left( {\left. \Lambda  \right|\xi } \right)} \right\} = \frac{{{{\left( {{\rm M}\left\{ {z\left( \xi  \right)} \right\}} \right)}^2}}}{{2{v^2}}}.
$$	
 
   
  

\section{ }

\subsection{Рисунки}
 
\begin{Figure}\centering%{l}{\linewidth}
\includegraphics[width=\linewidth]{fig1}
\captionof{figure}{Графік залежності помилки визначення висот об'єктів від значення базису стереознімання}\label{radap1627fig1}
\end{Figure}
 
\begin{figure*}\centering
	%Figure 5 	
	\includegraphics[width=0.4\linewidth]{fig2a}
	~~~~~
	\includegraphics[width=0.4\linewidth]{fig2b}
	\begin{tabular}{p{0.49\linewidth}p{0.49\linewidth}}
		\centering (a) & \centering (b)  
	\end{tabular}	
	\captionof{figure}{Підпис до рисунку (a) $\Delta\delta_{DD}(r_n)$ (b)  $\theta = 1 $}\label{fig2}%
\end{figure*}

\subsection{Оформлення таблиць}

Таблиця в одній колонці
\begin{Table}
	\captionof{table}{Назва таблиці}
	\begin{tabularx}{\linewidth}{|l|c|c|c|c|X|}
		\hline   &   &  &  &  &  \\
		\rule{0pt}{10pt}   &   &	 &	  & &	 \\ 
		\hline 
		\rule{0pt}{10pt}  &  &   &	  &	  &  \\ 
		\hline 
		\rule{0pt}{10pt}  &   &	 &	  &	  &	 \\ 
		\hline 
		\rule{0pt}{10pt}  &   &   &	  &	  & \\ 
		\hline 
		\rule{0pt}{10pt}   &	  &  &   &	  &  \\ 
		\hline 
\end{tabularx} \label{radap1725tab1}
\end{Table}

Таблиця на дві колонки
\end{multicols}
\begin{Table}
\captionof{table}{Назва таблиці 2}
\begin{tabularx}{\linewidth}{|l|c|c|c|c|X|}
	\hline   &   &  &  &  &  \\
	\rule{0pt}{10pt}   &   &	 &	  & &	 \\ 
	\hline 
	\rule{0pt}{10pt}  &  &   &	  &	  &  \\ 
	\hline 
	\rule{0pt}{10pt}  &   &	 &	  &	  &	 \\ 
	\hline 
	\rule{0pt}{10pt}  &   &   &	  &	  & \\ 
	\hline 
	\rule{0pt}{10pt}   &	  &  &   &	  &  \\ 
	\hline 
\end{tabularx} \label{radap1725tab2}
\end{Table}
\begin{multicols}{2}




\pdfbookmark[1]{Висновки}{conc}
\section*{Висновки}


\pdfbookmark[1]{References}{translit}
\renewcommand{\refname}{References}

\begin{thebibliography}{99}\footnotesize 

\bibitem{Zhou2023}
Zhou, Y., Wang, Y., Wang, X., \& Zhang, Y., 2023. Electromyography monitoring systems in rehabilitation: A review of current applications and future challenges. \textit{Electronics}, 12(7), p.1520. Available at: \url{https://doi.org/10.3390/electronics12071520} [Accessed 25 May 2025].

\bibitem{Xie2024}
Xie, P., Xu, M., Shen, T., Chen, J., Jiang, G., Xiao, J., \& Chen, X., 2024. A channel-fused gated temporal convolutional network for EMG-based gesture recognition. \textit{Biomedical Signal Processing and Control}, 95, 106408. Available at: \url{https://doi.org/10.1016/j.bspc.2024.106408} [Accessed 25 May 2025].

\bibitem{Merletti2020}
Merletti, R. \& Farina, D., 2020. Tutorial. Surface EMG detection, conditioning and pre-processing: Best practices. \textit{Journal of Electromyography and Kinesiology}, 54, p.102440. Available at: \url{https://doi.org/10.1016/j.jelekin.2020.102440} [Accessed 25 May 2025].

\bibitem{Plux2022}
Plux Biosignals, 2022. Where should I place my Electromyography (EMG) electrodes? Available at: \url{https://support.pluxbiosignals.com/knowledge-base/where-should-i-place-my-electromyography-emg-electrodes/} [Accessed 25 May 2025].

\bibitem{Chowdhury2013}
Chowdhury, R.H., Reaz, M.B.I., Ali, M.A.B.M., Bakar, A.A.A., Chellappan, K., \& Chang, T.G., 2013. Surface electromyography signal processing and classification techniques. \textit{Sensors}, 13(9), pp.12431–12466. Available at: \url{https://doi.org/10.3390/s130912431} [Accessed 25 May 2025].

\bibitem{Phinyomark2019}
Phinyomark, A., Campbell, E., \& Scheme, E., 2019. Surface electromyography (EMG) signal processing, classification, and practical considerations. In: G. Naik, ed., \textit{Biomedical Signal Processing}. Singapore: Springer, pp.3–29. Available at: \url{https://doi.org/10.1007/978-981-13-9097-5_1} [Accessed 25 May 2025].

\bibitem{Faust2018}
Faust, O., Hagiwara, Y., Hong, T.J., Lih, O.S. \& Acharya, U.R., 2018. Deep learning for healthcare applications based on physiological signals: A review. \textit{Computer Methods and Programs in Biomedicine}, 161, pp.1–13. Available at: \url{https://doi.org/10.1016/j.cmpb.2018.04.005} [Accessed 25 May 2025].

\bibitem{Wu2022}
Wu, D., Yang, J., \& Sawan, M., 2022. Transfer learning on electromyography (EMG) tasks: Approaches and beyond. \textit{arXiv preprint arXiv:2210.06295}. Available at: \url{https://arxiv.org/abs/2210.06295} [Accessed 25 May 2025].

\bibitem{Cote2019}
Côté-Allard, U., Fall, C.L., Campeau-Lecours, A., et al., 2019. Deep learning for electromyographic hand gesture signal classification using transfer learning. \textit{IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 27(4), pp.760–771. Available at: \url{https://doi.org/10.1109/TNSRE.2019.2896269} [Accessed 25 May 2025].

\bibitem{Ameri2020}
Ameri, A., Akhaee, M.A., Scheme, E. \& Englehart, K.B., 2020. A deep transfer learning approach to reducing the effect of electrode shift in EMG pattern recognition-based control. \textit{IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 28(2), pp.370–379. Available at: \url{https://doi.org/10.1109/TNSRE.2019.2962189} [Accessed 25 May 2025].

\bibitem{Shen2020}
Shen, S., Gu, K., Chen, X.-R., Lv, C.-X., \& Wang, R.-C., 2020. Gesture recognition through sEMG with wearable device based on deep learning. \textit{Mobile Networks and Applications}, 25(6), pp.2447–2458. Available at: \url{https://doi.org/10.1007/s11036-020-01590-8} [Accessed 25 May 2025].

\bibitem{Geng2016}
Geng, Y., Zhou, P. \& Li, G., 2016. Toward attenuating the impact of inter-session variability in myoelectric pattern recognition using adaptive sparse representation. \textit{Journal of NeuroEngineering and Rehabilitation}, 13(1), p.4. Available at: \url{https://doi.org/10.1186/s12984-015-0114-3} [Accessed 25 May 2025].

\bibitem{Lehmler2021}
Lehmler, S.J., Saif-ur-Rehman, M., Glasmachers, T. \& Iossifidis, I., 2021. Deep transfer-learning for patient specific model re-calibration: Application to sEMG-classification. \textit{arXiv preprint arXiv:2112.15019}. Available at: \url{https://arxiv.org/abs/2112.15019} [Accessed 25 May 2025].

\bibitem{Cote2019_3DC}
Côté-Allard, U., Campbell, E., Phinyomark, A., et al., 2019. A low-cost, wireless, 3D-printed custom armband for sEMG hand gesture recognition. \textit{Sensors}, 19(12), 2811. Available at: \url{https://doi.org/10.3390/s19122811} [Accessed 25 May 2025].

% Methods
\bibitem{LibEMG2023}
Campeau-Lecours, A., Bouchard, D., Côté-Allard, U. and Gosselin, B., 2023. LibEMG: An Open Source Library to Facilitate the Exploration of Myoelectric Control. \textit{IEEE Access}, 11, pp.88686–88702. Available at: \url{https://doi.org/10.1109/ACCESS.2023.3304544} [Accessed 25 May 2025].

\bibitem{Smith2011}
Smith, L.H., Hargrove, L.J., Lock, B.A. and Kuiken, T.A., 2011. Determining the optimal window length for pattern recognition-based myoelectric control: balancing the competing effects of classification error and controller delay. \textit{IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 19(2), pp.186--192. Available at: \url{https://doi.org/10.1109/TNSRE.2010.2100828} [Accessed 26 May 2025].

\bibitem{Rehman2018}
Rehman, M.Z.U., Waris, A., Gilani, S.O., Jochumsen, M., Niazi, I.K., Jamil, M., Farina, D. and Kamavuako, E.N., 2018. Multiday EMG-Based Classification of Hand Motions With Deep Learning Techniques. \textit{Sensors}, 18(8), p.2497. Available at: \url{https://doi.org/10.3390/s18082497} [Accessed 25 May 2025].

\bibitem{Oskoei2007}
Oskoei, M.A. and Hu, H., 2007. Myoelectric control systems—A survey. \textit{Biomedical Signal Processing and Control}, 2(4), pp.275–294. Available at: \url{https://doi.org/10.1016/j.bspc.2007.07.009} [Accessed 25 May 2025].

\end{thebibliography}