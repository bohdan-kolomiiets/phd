%
%

\pdfbookmark[1]{Introduction}{intro}
\section*{Introduction}

Surface electromyography (sEMG) is a non-invasive technique for monitoring muscle activity and is widely applied in rehabilitation, prosthetics, assistive robotics, and human–computer interaction~\cite{Zhou2023}. It supports gesture recognition, prosthetic control, and assessment of neuromuscular recovery~\cite{Xie2024}.

However, the utility of sEMG is limited by physiological and technical factors, particularly electrode placement. Minor variations in electrode position can lead to substantial differences in signal amplitude and frequency content due to anatomical variability~\cite{Merletti2020}. Additionally, signal quality is affected by skin impedance, motion artifacts, and muscle fatigue~\cite{Plux2022}.

Classical signal processing methods—including time- and frequency-domain analysis, wavelet transforms, and handcrafted features—have been widely used for EMG interpretation~\cite{Chowdhury2013}. These techniques are computationally efficient and interpretable but struggle to capture the complex spatiotemporal patterns of multichannel or dynamic sEMG data. Their generalization across subjects or sessions is also limited~\cite{Phinyomark2019}.

Deep learning, especially convolutional neural networks (CNNs), has advanced EMG processing by enabling automatic feature learning from raw signals. CNNs outperform traditional machine learning models like SVMs or decision trees in classification accuracy~\cite{Faust2018}. However, they require large, annotated datasets to generalize effectively—posing challenges in biomedical contexts where data collection is costly and time-consuming~\cite{Wu2022}.

Transfer learning has emerged as a solution, enabling pre-trained models to adapt to smaller, task-specific datasets. Strategies include fine-tuning the entire model, freezing earlier layers, or employing domain adaptation~\cite{Cote2019, Ameri2020}. Their effectiveness varies depending on the dataset and model architecture.

Recent advances in wearable electronics—such as flexible sensors, edge AI modules, and low-power microcontrollers—are making it feasible to deploy deep learning models for real-time sEMG analysis~\cite{Shen2020}. This convergence opens the door to intelligent, adaptive systems for physical activity monitoring and neurorehabilitation.

This study investigates transfer learning strategies for CNN-based sEMG gesture recognition, especially under constraints of limited subject-specific data.

\section{Statement of the Problem}

Despite the success of CNNs in EMG gesture classification, their performance declines significantly when applied across different subjects without retraining. This inter-subject variability limits the practicality of deploying EMG-based human–machine interfaces without per-user calibration~\cite{Cote2019, Geng2016}.

Transfer learning offers a promising way to address this issue by adapting models trained on one subject group to new individuals. However, its practical implementation—such as whether to fine-tune all layers or use fixed feature extractors—has not been thoroughly evaluated for sEMG tasks~\cite{Lehmler2021}.

Furthermore, most studies do not systematically compare transfer learning strategies using standardized datasets or rigorous evaluation protocols. As a result, there is little guidance on which methods offer the best accuracy and stability, particularly when subject-specific data is scarce.

This work aims to fill this gap by experimentally comparing two transfer learning strategies on a real-world sEMG dataset: (1) fine-tuning with the reset of the fully connected (FC) output layer and (2) fine-tuning without resetting the FC layer. We assess classification accuracy and model variance on the 3DC dataset~\cite{Cote2019_3DC}, and investigate whether these methods can reduce the amount of required subject-specific data while maintaining or improving performance.

\section{Dataset}

The \textit{3DC Dataset} dataset comprises surface electromyography (sEMG) recordings collected from 22 able-bodied participants performing eleven distinct hand and wrist gestures. Each subject completed eight repetitions of a predefined gesture sequence, resulting in a substantial volume of labeled gesture data.

The 3DC Dataset was introduced in the work by Côté-Allard et al.~\cite{Cote2019_3DC}, where the authors designed a low-cost, 3D-printed, wireless myoelectric armband known as the 3DC Armband. This device features 10 dry sEMG electrodes and a 9-axis inertial measurement unit (IMU), with a sampling rate of 1000 Hz. The data acquisition protocol involved placing the 3DC Armband on the dominant forearm of each participant, alternating the armband's position relative to the elbow between participants to simulate real-world variability in wearability.

Subjects were instructed to perform eleven gestures—such as wrist flexion, extension, and different hand shapes—each held for 5 seconds per repetition. These recordings were organized into eight continuous cycles of data acquisition, separated by a 5-minute rest period between the fourth and fifth cycles.

Due to the diverse electrode placement protocols used in the original study to simulate real-world variability, substantial intra- and inter-subject signal differences are present. One the one hand, it challenges the generalization capability of learned models, and on the other hand - it makes this dataset a good benchmark for evaluating inter-subject generalization and transfer learning strategies in sEMG-based gesture classification.

\section{Methods}

The research was conducted using the \texttt{LibEMG} Python library~\cite{LibEMG2023}, which provides a unified framework for data loading, preprocessing, training, and evaluation of machine learning models in electromyographic control systems.

As recent deep learning studies suggest, the raw sEMG signal can be ingested directly for gesture classification~\cite{Oskoei2007,Rehman2018,Cote2019}.

Adhering to the already existing best-practices~\cite{Smith2011} and works that use chosen dataset~\cite{Cote2019_3DC,LibEMG2023}, in this study, raw EMG signals are split into 200-sample overlapping windows (with a step size of 100) forming matrixes of size $10 \times 200$ that serves as the input to our CNN. 

\subsection*{CNN Architecture}
The CNN architecture used in this study is based on implementations from works~\cite{Cote2019_3DC,LibEMG2023}. 
The final architecture used in this study consists of three sequential 1D convolutional layers followed by a fully connected (FC) output layer. The network was designed to process raw surface EMG input of shape $10 \times 200$ (channels × samples), where each input segment corresponds to a 200-sample window of 10-channel EMG data.
Each convolutional block includes a \texttt{Conv1d} layer with kernel size 5, followed by batch normalization and a ReLU activation function. The number of filters in successive convolutional layers tapers from 64 to 32 and then 16, forming a pyramid structure that progressively condenses features. The output of the final convolutional layer is flattened and passed to a fully connected layer of size 3008 $\rightarrow$ 11, where 11 corresponds to the number of gesture classes.
Weights for all layers were initialized using Glorot (Xavier) uniform initialization, and biases were set to zero. The network was optimized using the Adam optimizer (initial learning rate of $10^{-3}$) with a cosine annealing learning rate schedule and trained using cross-entropy loss. Early stopping was applied with a patience of four epochs and tolerance threshold of 0.03. A maximum of 50 epochs was allowed during training, although convergence typically occurred within 15 epochs. To ensure reproducibility, all random seeds were explicitly set for PyTorch, NumPy, and Python’s built-in generators.
The exact implementation of the CNN used in this study is available in the publicly accessible repository~\cite{Kolomiiets2025}.

\subsection*{Evaluated training approaches}

Three training approaches were evaluated:

\begin{itemize}
    \item \textbf{Intra-subject (single-subject) training}: The model was trained and tested on different gesture repetitions from the same participant. We applied leave-one-out cross-validation strategy for repetitions, choosing one repetition as test set, one repetition as validation set during training, and six remained for training itself within each subject. Such cross-validation yields 65 folds per subject.
    \item \textbf{Inter-subject (cross-subject) generalization}: The model was trained on 21 subjects and tested on the one excluded subject. The same leave-one-out cross-validation strategy for repetitions was applied per each excluded subject.
    \item \textbf{Transfer learning}: The best pre-trained cross-subject models were fine-tuned on subject-specific data using two strategies: (1) resetting the final FC layer before fine-tuning and (2) preserving the final FC layer weights before fine-tuning. All convolutional layers remained trainable during fine-tuning.
\end{itemize}

Additionally, to evaluate whether the transfer learning approach with FC layer reset still outperforms training from scratch when less subject-specific data is available, we repeated the ''Intra-subject'' and ''Transfer learning’’ experiments using fewer training repetitions. While the original experiments used 6 out of 8 available repetitions for training, the new experiments were conducted using only 4, 2, and 1 repetitions for training itself to simulate more limited data scenarios.

To compare the effectiveness of transfer learning approaches, Wilcoxon signed-rank tests were performed for all experiments.

\section{Results and discussion}

To evaluate the performance of different training approaches, F1-score was selected as the primary accuracy metric.

\subsection*{Compare training approaches}

Figure~\ref{fig:boxplot-approaches} presents box-and-whisker plots summarizing the F1-score distributions for inter-subject generalization, intra-subject training, and two transfer learning strategies: fine-tuning with and without resetting the fully connected (FC) layer. All eight available repetitions were used for training in those experiments. Consequently, distributions are based on $1232 (8*7*22)$ cross-validation folds per training approach across all 22 subjects.

The inter-subject approach yielded a mean F1-score of 0.382 ($\sigma = 0.149$), confirming that generalization across subjects is significantly limited due to variability in electrode placement and anatomical differences. In contrast, intra-subject training—where the model is trained and tested on data from the same participant—achieved a dramatically higher mean F1-score of 0.869 ($\sigma = 0.089$).

Fine-tuning pre-trained models using the ``without FC reset'' transfer learning strategy further improved performance to 0.896 ($\sigma = 0.071$). However, the best result was obtained using the ``with FC reset'' transfer learning strategy, achieving a mean of 0.907 ($\sigma = 0.074$), suggesting that resetting the CNN's head enables better adaptation to new subjects. Both transfer learning strategies outperformed intra-subject training approach, affirming the benefit of using pre-trained models.

\subsection*{Evaluate the effect of reduced subject-specific data}

To assess whether transfer learning allowes to reduce the amount of subject-specific data, we additionally performed experiments with decreased numbers of training repetitions (6, 4, 3). As shown in Figure~\ref{fig:boxplot-reps}, the transfer learning approach with FC layer reset consistently achieves higher F1-scores across all scenarios. While reducing the number of training repetitions to three results in a noticeable decline in accuracy, using four repetitions yields only a modest decrease. This effectively halves the required subject effort compared to using all eight repetitions, without substantially compromising classification accuracy.

\end{multicols}

\begin{center}
\centering%{l}{\linewidth}
\includegraphics[width=\linewidth]{accuracy_by_approach_8_reps}
\captionof{figure}{Box-and-whisker plots of F1-score distributions across training approaches: ''Inter-subject', ''Intra-subject'' training approaches, and two fine-tuning (FT) strategies in transfer learning (TL) approach: with and without fully connected (FC) layer reset. Boxes represent interquartile range (IQR), lines show medians, and dashed lines indicate means. Outliers are shown as individual points.}
\label{fig:boxplot-approaches}
\end{center}

\begin{center}
\centering%{l}{\linewidth}
\includegraphics[width=\linewidth]{intra_subject_vs_fine_tuned_by_reps}
\captionof{figure}{Box-and-whisker plots showing the distribution of F1-scores across different numbers of training repetitions (6, 4, 2, 1) for ''Intra-subject'' and ''Transfer learning'' (TL) approach with fully connected (FC) layer reset. Note that repetitions numbers here represent a total number of repetitions consisting of eleven gestures a subject would need to execute to achieve shown accuracy. Each box shows the interquartile range and median; dashed lines denote the mean. Outliers are plotted as individual points.}
\label{fig:boxplot-reps}
\end{center}
\begin{multicols}{2}

\subsection*{Statistical significance of transfer learning improvements}

To formally test the impact of transfer learning approaches, we performed Wilcoxon signed-rank tests on the subject-wise mean and standard deviation (STD) of F1-scores with significance level $\alpha = 0.05$.\newline

\textbf{Comparing training approaches with all available training repetitions used.}  

Below are results of the statistical analysis when using all eight repetitions were used.

- \textit{''Intra-subject'' vs ''Transfer Learning'' without FC reset:} The mean F1-score increased from $0.869$ to $0.896$. Wilcoxon test ($p = 7.87 \times 10^{-6}$) confirmed a statistically significant improvement. However, the decrease in STD from 0.089 to 0.071 was not statistically significant ($p = 0.0829$).

- \textit{''Intra-subject'' vs ''Transfer Learning'' with FC reset:} The mean F1-score increased to $0.907$. Wilcoxon test ($p = 2.38 \times 10^{-7}$) confirmed this improvement to be statistically significant. Additionally, the reduction in STD from 0.089 to 0.074 was also statistically significant ($p = 0.00162$), indicating enhanced model stability.

- \textit{''Transfer Learning'' without FC reset vs ''Transfer Learning'' with FC reset:} The ``with FC reset'' strategy outperformed ``without reset'' in mean F1-score (0.907 vs 0.896), with Wilcoxon test yielding $p = 0.000346$, indicating statistical significance. The change in STD was not statistically significant ($p = 0.118$).\newline

\textbf{Effect of reducing number of repetitions.}  

To validate whether transfer learning with FC reset remains statistically superior to training from the scratch (intra-subject approach) when fewer training repetitions are used, Wilcoxon tests were also conducted for 6, 4, and 3 repetitions.

- \textit{6 repetitions:} F1-score improved from 0.822 to 0.883 ($p = 2 \times 10^{-5}$); STD statistically significantly reduced from 0.103 to 0.084 ($p = 0.0333$).

- \textit{4 repetitions:} F1-score improved from 0.711 to 0.841 ($p = 2 \times 10^{-5}$); STD statistically significantly reduced from 0.107 to 0.084 ($p = 0.00183$).

- \textit{3 repetitions:} F1-score improved from 0.463 to 0.724 ($p = 2 \times 10^{-5}$); STD statistically significantly reduced from 0.127 to 0.121 ($p = 0.0473$). \newline

These results demonstrate that the benefit of transfer learning with FC reset remains statistically significant across differnet amount of available training data. This confirms its robustness and practicality for reducing subject burden during calibration.

The training results, as well as python scripts used to analyse those results are available in the publicly accessible repository~\cite{Kolomiiets2025}.

\subsection*{Summary of findings}

In summary:
\begin{itemize}
    \item Both transfer learning strategies outperform training from scratch in terms of classification accuracy.
    \item Fine-tuning with FC reset consistently outperforms the strategy without FC reset.
    \item Fine-tuning with FC reset provides greater model stability than training from scratch.
    \item Transfer learning with FC reset achieves comparable accuracy while requiring less subject-specific data.
\end{itemize}

These findings validate the efficacy of transfer learning for sEMG gesture recognition and highlight the practical advantage of using pre-trained models for quick subject adaptation, especially in real-time or low-data scenarios.

\subsection*{Limitations, Comparison to Related Work, and Future Directions}

While the experimental results strongly support the effectiveness of transfer learning—particularly the fine-tuning with FC reset strategy—several limitations should be acknowledged.

First, the convolutional neural network (CNN) architecture employed in this study was intentionally kept relatively shallow to ensure comparability with related works and maintain computational simplicity~\cite{Cote2019_3DC,LibEMG2023}. However, this architecture may not fully exploit the temporal and spatial dependencies in sEMG signals. More advanced architectures, such as gated temporal convolutional networks~\cite{Xie2024} or hybrid CNN–LSTM models~\cite{Faust2018}, could potentially further improve classification performance and stability.

Second, although the 3DC dataset is a good benchmark, it was originally designed to simulate realistic variability in electrode placement. While this is usefull for evaluating inter-subject generalization, it also introduces significant variability in the training data. As a result, absolute accuracy values reported in this study may be lower than those observed in more controlled datasets.

Third, although our experiments employed leave-one-out cross-validation per subject and repetition, they were conducted in an offline setting. Future evaluations in real-time or online scenarios are necessary to validate the practicality of deploying these models in wearable systems or interactive applications~\cite{Shen2020}.

In comparison to related studies, our results are consistent with prior works by Côté-Allard et al.~\cite{Cote2019}, who demonstrated the benefits of transfer learning on sEMG-based gesture recognition. However, those studies typically used a single transfer learning strategy. Our work expands upon this by systematically comparing fine-tuning with and without FC reset and providing robust statistical analysis. Furthermore, while Lehmler et al.~\cite{Lehmler2021} and Ameri et al.~\cite{Ameri2020} investigated domain adaptation and transfer across electrode shifts, few works have directly quantified how much subject-specific data can be saved—a contribution this paper explicitly addresses.

Future research may focus on several directions:
\begin{itemize}
    \item Exploring deeper or hybrid models that can model temporal dynamics explicitly (e.g., attention-based or transformer architectures).
    \item Incorporating domain adaptation techniques to further mitigate distributional shifts between training and target subjects.
    \item Investigating few-shot or semi-supervised learning approaches to reduce calibration requirements even further.
    \item Evaluating latency and resource usage for deployment on low-power microcontrollers to ensure feasibility in wearable devices.
\end{itemize}

In addition, public benchmarking on larger and more diverse datasets would help generalize these findings to broader use cases. The proposed evaluation pipeline based on \texttt{LibEMG} and 3DC can serve as a reproducible and extensible framework for future comparisons.

\section*{Conclusion}

This study investigated the effectiveness of transfer learning for surface electromyography (sEMG) gesture classification using convolutional neural network (CNN). By comparing intra-subject training, inter-subject generalization, and two transfer learning strategies (with and without resetting the FC layer), we demonstrated that transfer learning significantly enhances classification performance and model stability.

Our experiments showed that fine-tuning pre-trained models—especially when resetting the FC layer—not only improves F1-scores but also reduces standard deviation across cross-validation folds, indicating more consistent performance. Notably, this benefit remains statistically significant even when using a reduced number of repetitions for subject-specific fine-tuning, suggesting that transfer learning can substantially reduce the effort required for user calibration.

In addition, the statistical analysis using Wilcoxon signed-rank tests confirmed the superiority of the fine-tuned models under various data constraints. These findings emphasize the practicality of transfer learning in real-world applications where data availability is limited.

Nevertheless, the study has several limitations. The CNN architecture used is relatively simple and may not capture more complex spatiotemporal dependencies in the EMG signal. Also, evaluations were conducted in an offline setting using a single dataset (3DC), which, while realistic in variability, may not generalize to all EMG acquisition systems or environments.

Future works could explore deeper and hybrid models, real-time implementations, and domain adaptation techniques to further reduce calibration overhead. Expanding evaluation to diverse datasets and hardware platforms will be critical to validating these results at scale.

In summary, transfer learning—particularly fine-tuning with FC reset—emerges as a highly effective strategy for subject adaptation in sEMG-based gesture recognition, offering performance and stability improvements, as well as reducing amount of training data needed.

\pdfbookmark[1]{References}{translit}
\renewcommand{\refname}{References}

\begin{thebibliography}{99}\footnotesize 

\bibitem{Zhou2023}
Zhou, Y., Wang, Y., Wang, X., \& Zhang, Y., 2023. Electromyography monitoring systems in rehabilitation: A review of current applications and future challenges. \textit{Electronics}, 12(7), p.1520. Available at: \url{https://doi.org/10.3390/electronics12071520} [Accessed 25 May 2025].

\bibitem{Xie2024}
Xie, P., Xu, M., Shen, T., Chen, J., Jiang, G., Xiao, J., \& Chen, X., 2024. A channel-fused gated temporal convolutional network for EMG-based gesture recognition. \textit{Biomedical Signal Processing and Control}, 95, 106408. Available at: \url{https://doi.org/10.1016/j.bspc.2024.106408} [Accessed 25 May 2025].

\bibitem{Merletti2020}
Merletti, R. \& Farina, D., 2020. Tutorial. Surface EMG detection, conditioning and pre-processing: Best practices. \textit{Journal of Electromyography and Kinesiology}, 54, p.102440. Available at: \url{https://doi.org/10.1016/j.jelekin.2020.102440} [Accessed 25 May 2025].

\bibitem{Plux2022}
Plux Biosignals, 2022. Where should I place my Electromyography (EMG) electrodes? Available at: \url{https://support.pluxbiosignals.com/knowledge-base/where-should-i-place-my-electromyography-emg-electrodes/} [Accessed 25 May 2025].

\bibitem{Chowdhury2013}
Chowdhury, R.H., Reaz, M.B.I., Ali, M.A.B.M., Bakar, A.A.A., Chellappan, K., \& Chang, T.G., 2013. Surface electromyography signal processing and classification techniques. \textit{Sensors}, 13(9), pp.12431–12466. Available at: \url{https://doi.org/10.3390/s130912431} [Accessed 25 May 2025].

\bibitem{Phinyomark2019}
Phinyomark, A., Campbell, E., \& Scheme, E., 2019. Surface electromyography (EMG) signal processing, classification, and practical considerations. In: G. Naik, ed., \textit{Biomedical Signal Processing}. Singapore: Springer, pp.3–29. Available at: \url{https://doi.org/10.1007/978-981-13-9097-5_1} [Accessed 25 May 2025].

\bibitem{Faust2018}
Faust, O., Hagiwara, Y., Hong, T.J., Lih, O.S. \& Acharya, U.R., 2018. Deep learning for healthcare applications based on physiological signals: A review. \textit{Computer Methods and Programs in Biomedicine}, 161, pp.1–13. Available at: \url{https://doi.org/10.1016/j.cmpb.2018.04.005} [Accessed 25 May 2025].

\bibitem{Wu2022}
Wu, D., Yang, J., \& Sawan, M., 2022. Transfer learning on electromyography (EMG) tasks: Approaches and beyond. \textit{arXiv preprint arXiv:2210.06295}. Available at: \url{https://arxiv.org/abs/2210.06295} [Accessed 25 May 2025].

\bibitem{Cote2019}
Côté-Allard, U., Fall, C.L., Campeau-Lecours, A., et al., 2019. Deep learning for electromyographic hand gesture signal classification using transfer learning. \textit{IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 27(4), pp.760–771. Available at: \url{https://doi.org/10.1109/TNSRE.2019.2896269} [Accessed 25 May 2025].

\bibitem{Ameri2020}
Ameri, A., Akhaee, M.A., Scheme, E. \& Englehart, K.B., 2020. A deep transfer learning approach to reducing the effect of electrode shift in EMG pattern recognition-based control. \textit{IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 28(2), pp.370–379. Available at: \url{https://doi.org/10.1109/TNSRE.2019.2962189} [Accessed 25 May 2025].

\bibitem{Shen2020}
Shen, S., Gu, K., Chen, X.-R., Lv, C.-X., \& Wang, R.-C., 2020. Gesture recognition through sEMG with wearable device based on deep learning. \textit{Mobile Networks and Applications}, 25(6), pp.2447–2458. Available at: \url{https://doi.org/10.1007/s11036-020-01590-8} [Accessed 25 May 2025].

\bibitem{Geng2016}
Geng, Y., Zhou, P. \& Li, G., 2016. Toward attenuating the impact of inter-session variability in myoelectric pattern recognition using adaptive sparse representation. \textit{Journal of NeuroEngineering and Rehabilitation}, 13(1), p.4. Available at: \url{https://doi.org/10.1186/s12984-015-0114-3} [Accessed 25 May 2025].

\bibitem{Lehmler2021}
Lehmler, S.J., Saif-ur-Rehman, M., Glasmachers, T. \& Iossifidis, I., 2021. Deep transfer-learning for patient specific model re-calibration: Application to sEMG-classification. \textit{arXiv preprint arXiv:2112.15019}. Available at: \url{https://arxiv.org/abs/2112.15019} [Accessed 25 May 2025].

\bibitem{Cote2019_3DC}
Côté-Allard, U., Campbell, E., Phinyomark, A., et al., 2019. A low-cost, wireless, 3D-printed custom armband for sEMG hand gesture recognition. \textit{Sensors}, 19(12), 2811. Available at: \url{https://doi.org/10.3390/s19122811} [Accessed 25 May 2025].

% Methods
\bibitem{LibEMG2023}
Campeau-Lecours, A., Bouchard, D., Côté-Allard, U. and Gosselin, B., 2023. LibEMG: An Open Source Library to Facilitate the Exploration of Myoelectric Control. \textit{IEEE Access}, 11, pp.88686–88702. Available at: \url{https://doi.org/10.1109/ACCESS.2023.3304544} [Accessed 25 May 2025].

\bibitem{Smith2011}
Smith, L.H., Hargrove, L.J., Lock, B.A. and Kuiken, T.A., 2011. Determining the optimal window length for pattern recognition-based myoelectric control: balancing the competing effects of classification error and controller delay. \textit{IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 19(2), pp.186--192. Available at: \url{https://doi.org/10.1109/TNSRE.2010.2100828} [Accessed 26 May 2025].

\bibitem{Rehman2018}
Rehman, M.Z.U., Waris, A., Gilani, S.O., Jochumsen, M., Niazi, I.K., Jamil, M., Farina, D. and Kamavuako, E.N., 2018. Multiday EMG-Based Classification of Hand Motions With Deep Learning Techniques. \textit{Sensors}, 18(8), p.2497. Available at: \url{https://doi.org/10.3390/s18082497} [Accessed 25 May 2025].

\bibitem{Oskoei2007}
Oskoei, M.A. and Hu, H., 2007. Myoelectric control systems—A survey. \textit{Biomedical Signal Processing and Control}, 2(4), pp.275–294. Available at: \url{https://doi.org/10.1016/j.bspc.2007.07.009} [Accessed 25 May 2025].

\bibitem{Kolomiiets2025}
Kolomiiets, B. Yu., 2025. *Code used for experiments presented in this artcile* [online]. GitHub. Available at: \url{https://github.com/bohdan-kolomiiets/phd-article-1} [Accessed 27 May 2025].

\end{thebibliography}